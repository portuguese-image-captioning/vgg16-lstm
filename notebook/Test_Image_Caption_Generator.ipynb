{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#Keras\n",
    "#Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#NTLK\n",
    "import nltk\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#corpus-bleu evaluation metrics\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tensorflow.keras.layers import Input\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import Image,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10387594718386175524\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254123828\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16629678345834780323\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOKENIZER_PATH = \"D:/SiDi/Project/Modulo III/dataset/train_tokenizer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "def word_for_id(integer , tokenizer):\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "        \n",
    "def generate_desc(model , tokenizer , photo , max_length):\n",
    "    \n",
    "    input_text = 'startseq'\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        sequence = pad_sequences([sequence] , maxlen=max_length)\n",
    "        # predict the next word\n",
    "        next_word_id = model.predict([photo,sequence],verbose = 0)\n",
    "        \n",
    "        # get highest probality word from list of words\n",
    "        next_word_id = np.argmax(next_word_id)\n",
    "        \n",
    "        # get word from id\n",
    "        word = word_for_id(next_word_id , tokenizer)\n",
    "        \n",
    "        if word is None:\n",
    "            break\n",
    "            \n",
    "        # update input text\n",
    "        input_text += ' '+ word\n",
    "        \n",
    "        if word == 'endseq':\n",
    "            break\n",
    "            \n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_one_image(filename):\n",
    "    \"\"\"model = VGG16()\n",
    "    model.layers.pop()\n",
    "    \n",
    "    model = Model(inputs = model.inputs , outputs = model.layers[-1].output)\n",
    "    \n",
    "    #image = load_img(filename , target_size=(224,224))\"\"\"\n",
    "    model = VGG16()   \n",
    "    #model = VGG16( include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "    #remove last layer\n",
    "    model = Model(inputs = model.inputs , outputs = model.layers[-2].output)\n",
    "\n",
    "    image = load_img(filename , target_size=(224,224))\n",
    "\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    image = image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
    "    \n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    feature = model.predict(image , verbose = 0)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "def get_image_caption(filename,model):\n",
    "    tokenizer = load(open(TRAIN_TOKENIZER_PATH,'rb'))\n",
    "    photo = extract_features_for_one_image(filename)\n",
    "    gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "    type(gpus)\n",
    "    if gpus:\n",
    "      # Replicate your computation on multiple GPUs\n",
    "      c = []\n",
    "      for gpu in gpus:\n",
    "        with tf.device(gpu.name):\n",
    "            print(gpu.name)\n",
    "            pass\n",
    "    gpu = gpus[0]\n",
    "    \n",
    "    with tf.device(gpu.name):\n",
    "        desc = generate_desc(model , tokenizer , photo , 64)\n",
    "        desc = desc.replace('startseq','')\n",
    "        desc = desc.replace('endseq','')\n",
    "    return desc.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =  load_model('./model/final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      " Um Gato Está Sentado Em Uma Cadeira De Madeira \n"
     ]
    }
   ],
   "source": [
    "filename = './test/000000363784.jpg'\n",
    "print(get_image_caption(filename,model2))\n",
    "#display(Image(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cópia de Image Caption Generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "image-caption-generator",
   "language": "python",
   "name": "image-caption-generator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
